# Advanced Sampling Strategy Evaluation Framework for Imbalanced Classification

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix
import xgboost as xgb
from imblearn.over_sampling import (
    SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE, 
    RandomOverSampler, KMeansSMOTE
)
from imblearn.under_sampling import (
    RandomUnderSampler, TomekLinks, EditedNearestNeighbours,
    NeighbourhodCleaningRule, OneSidedSelection
)
from imblearn.combine import (
    SMOTEENN, SMOTETomek
)
from imblearn.pipeline import Pipeline as ImbPipeline
import warnings
warnings.filterwarnings('ignore')

class SamplingStrategyEvaluator:
    """
    Comprehensive evaluation of different sampling strategies with multiple models
    """
    
    def __init__(self, X, y, cv_folds=5, random_state=42):
        self.X = X
        self.y = y
        self.cv_folds = cv_folds
        self.random_state = random_state
        self.results_df = pd.DataFrame()
        
        # Calculate class distribution
        self.class_distribution = pd.Series(y).value_counts().sort_index()
        self.minority_class_ratio = min(self.class_distribution) / sum(self.class_distribution)
        
        print(f"Original class distribution: {dict(self.class_distribution)}")
        print(f"Minority class ratio: {self.minority_class_ratio:.4f}")
    
    def get_sampling_strategies(self):
        """
        Define various sampling strategies to test
        """
        sampling_strategies = {
            # No Sampling (Baseline)
            'No_Sampling': None,
            
            # Over-sampling techniques
            'SMOTE': SMOTE(random_state=self.random_state),
            'SMOTE_50_50': SMOTE(sampling_strategy=0.5, random_state=self.random_state),
            'SMOTE_70_30': SMOTE(sampling_strategy=0.7, random_state=self.random_state),
            'SMOTE_80_20': SMOTE(sampling_strategy=0.8, random_state=self.random_state),
            
            'ADASYN': ADASYN(random_state=self.random_state),
            'BorderlineSMOTE': BorderlineSMOTE(random_state=self.random_state),
            'SVMSMOTE': SVMSMOTE(random_state=self.random_state),
            'KMeansSMOTE': KMeansSMOTE(random_state=self.random_state),
            'RandomOverSampler': RandomOverSampler(random_state=self.random_state),
            
            # Under-sampling techniques
            'RandomUnderSampler': RandomUnderSampler(random_state=self.random_state),
            'TomekLinks': TomekLinks(),
            'EditedNearestNeighbours': EditedNearestNeighbours(),
            'NeighbourhodCleaningRule': NeighbourhodCleaningRule(),
            'OneSidedSelection': OneSidedSelection(random_state=self.random_state),
            
            # Combined techniques
            'SMOTETomek': SMOTETomek(random_state=self.random_state),
            'SMOTEENN': SMOTEENN(random_state=self.random_state),
            
            # Custom ratios for specific business needs
            'SMOTE_Custom_10x': SMOTE(
                sampling_strategy={1: int(len(self.y[self.y==0]) * 0.1)}, 
                random_state=self.random_state
            ),
            'SMOTE_Custom_5x': SMOTE(
                sampling_strategy={1: int(len(self.y[self.y==0]) * 0.2)}, 
                random_state=self.random_state
            ),
        }
        
        return sampling_strategies
    
    def get_models(self):
        """
        Define models with class imbalance handling
        """
        models = {
            'RandomForest': RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                min_samples_split=5,
                min_samples_leaf=2,
                class_weight='balanced',
                random_state=self.random_state,
                n_jobs=-1
            ),
            
            'RandomForest_NoWeight': RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=self.random_state,
                n_jobs=-1
            ),
            
            'XGBoost': xgb.XGBClassifier(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                scale_pos_weight=len(self.y[self.y==0]) / len(self.y[self.y==1]),
                random_state=self.random_state,
                n_jobs=-1,
                eval_metric='logloss'
            ),
            
            'XGBoost_NoWeight': xgb.XGBClassifier(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=self.random_state,
                n_jobs=-1,
                eval_metric='logloss'
            ),
            
            'GradientBoosting': GradientBoostingClassifier(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=6,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=self.random_state
            ),
            
            'AdaBoost': AdaBoostClassifier(
                n_estimators=100,
                learning_rate=1.0,
                random_state=self.random_state
            )
        }
        
        return models
    
    def evaluate_combination(self, model_name, model, sampling_name, sampling_strategy, 
                           custom_evaluate_func=None):
        """
        Evaluate a specific model-sampling combination
        """
        try:
            if sampling_strategy is None:
                # No sampling, use model directly
                pipeline = model
            else:
                # Create pipeline with sampling
                pipeline = ImbPipeline([
                    ('sampling', sampling_strategy),
                    ('classifier', model)
                ])
            
            # Cross-validation
            cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, 
                               random_state=self.random_state)
            
            # If custom evaluate function is provided, use it
            if custom_evaluate_func:
                scores = custom_evaluate_func(pipeline, self.X, self.y, cv)
            else:
                # Default scoring metrics
                scoring_metrics = ['accuracy', 'precision', 'recall', 'f1']
                scores = {}
                for metric in scoring_metrics:
                    scores[metric] = cross_val_score(
                        pipeline, self.X, self.y, cv=cv, 
                        scoring=metric, n_jobs=-1
                    ).mean()
            
            result = {
                'Model': model_name,
                'Sampling_Strategy': sampling_name,
                'Accuracy': scores.get('accuracy', scores.get('test_accuracy', 0)),
                'Precision': scores.get('precision', scores.get('test_precision', 0)),
                'Recall': scores.get('recall', scores.get('test_recall', 0)),
                'F1_Score': scores.get('f1', scores.get('test_f1', 0))
            }
            
            return result
            
        except Exception as e:
            print(f"Error with {model_name} + {sampling_name}: {str(e)}")
            return None
    
    def run_comprehensive_evaluation(self, custom_evaluate_func=None):
        """
        Run evaluation for all model-sampling combinations
        """
        models = self.get_models()
        sampling_strategies = self.get_sampling_strategies()
        
        results = []
        total_combinations = len(models) * len(sampling_strategies)
        current_combination = 0
        
        print(f"Starting evaluation of {total_combinations} combinations...")
        print("-" * 60)
        
        for model_name, model in models.items():
            for sampling_name, sampling_strategy in sampling_strategies.items():
                current_combination += 1
                print(f"[{current_combination}/{total_combinations}] Testing: {model_name
